# =====================================================================
# NGINX SITE CONFIGURATION FOR REVELO IMAGE GALLERY
# =====================================================================
# This file defines how nginx handles requests for your Revelo application.
# It sets up reverse proxy routing to your backend services and serves
# static files directly for optimal performance.

# =====================================================================
# UPSTREAM DEFINITIONS - BACKEND SERVICE CONNECTIONS
# =====================================================================
# Upstream blocks define pools of backend servers that nginx can
# forward requests to. This enables load balancing and failover.

# API backend service (Node.js/Express application)
upstream api {
    # Docker service name and port where the API container is running
    server api:${API_PORT};
    
    # Keep 32 idle connections open to the API server
    # This improves performance by reusing connections instead of
    # creating new ones for each request
    keepalive 32;
}

# Frontend client service (Vue.js application served by nginx)
upstream client {
    # Docker service name and port where the client container is running
    server client:80;
    
    # Keep 32 idle connections open to the client server
    keepalive 32;
}

# =====================================================================
# HTTP SERVER BLOCK - HANDLES ALL WEB TRAFFIC
# =====================================================================
# This server block handles all incoming HTTP requests on port 80
# In production, you would typically redirect HTTP to HTTPS
server {
    # Listen on port 80 for all HTTP requests
    listen ${NGINX_PORT};
    
    # Server name - underscore means "match any domain"
    # In production, replace with your actual domain name
    server_name _;

    # =================================================================
    # HEALTH CHECK ENDPOINT
    # =================================================================
    # Simple endpoint for monitoring systems to check if nginx is alive
    # Returns "healthy" with HTTP 200 status
    location /health {
        # Don't log health check requests (reduces log noise)
        access_log off;
        
        # Return simple "healthy" response
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }

    # =================================================================
    # HTTPS REDIRECT (FOR PRODUCTION)
    # =================================================================
    # In production with SSL certificates, uncomment the next line to
    # automatically redirect all HTTP traffic to HTTPS for security:
    # return 301 https://$server_name$request_uri;

    # =================================================================
    # API ROUTES - BACKEND APPLICATION REQUESTS
    # =================================================================
    # All requests starting with /api/ are forwarded to the Node.js API
    # The trailing slash is important - it strips "/api" from the forwarded URL
    location /api/ {
        # Apply rate limiting from the "api" zone defined in nginx.conf
        # burst=50 allows temporary spikes up to 50 requests above the limit
        # nodelay processes burst requests immediately instead of queuing them
        limit_req zone=api burst=50 nodelay;

        # Forward to the API upstream, stripping the "/api" prefix
        # Request to /api/images becomes /images when sent to the API
        proxy_pass http://api/;
        
        # Use HTTP/1.1 for better performance and connection reuse
        proxy_http_version 1.1;
        
        # Headers needed for WebSocket support (if your app uses them)
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        
        # Pass the original Host header to the backend
        proxy_set_header Host $host;
        
        # Pass the real client IP address to the backend
        proxy_set_header X-Real-IP $remote_addr;
        
        # Build a chain of forwarded IP addresses (for multiple proxies)
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        
        # Tell the backend whether the original request was HTTP or HTTPS
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Disable caching for WebSocket upgrade requests
        proxy_cache_bypass $http_upgrade;

        # Connection timeouts (prevent hanging connections)
        proxy_connect_timeout 30s;  # Time to connect to backend
        proxy_send_timeout 30s;     # Time to send request to backend
        proxy_read_timeout 30s;     # Time to read response from backend
    }

    # =================================================================
    # UPLOAD ROUTES - FILE UPLOAD HANDLING
    # =================================================================
    # Special handling for file uploads with higher timeout limits
    # and dedicated rate limiting
    location /api/upload {
        # Apply upload-specific rate limiting (slower than API limits)
        # burst=20 allows temporary spikes above the base rate
        limit_req zone=uploads burst=20 nodelay;

        # Forward to the API's upload endpoint
        proxy_pass http://api/upload;
        
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Extended timeouts for large file uploads
        proxy_connect_timeout 60s;   # 1 minute to connect
        proxy_send_timeout 300s;     # 5 minutes to upload file
        proxy_read_timeout 300s;     # 5 minutes to process upload

        # Override global upload size limit specifically for uploads
        client_max_body_size 100M;
    }

    # =================================================================
    # STATIC IMAGE SERVING VIA API - NO RATE LIMITING
    # =================================================================
    # Handle static image requests through the API without rate limiting
    # These are requests to /api/uploads/* for thumbnails, regular, etc.
    location /api/uploads/ {
        # No rate limiting for static image serving
        # Forward to the API's static file endpoint
        proxy_pass http://api/uploads/;

        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Standard timeouts for static file serving
        proxy_connect_timeout 30s;
        proxy_send_timeout 30s;
        proxy_read_timeout 30s;

        # Aggressive caching for images (they don't change once uploaded)
        expires 1y;
        add_header Cache-Control "public, immutable";
    }

    # =================================================================
    # STATIC IMAGE SERVING - DIRECT FILE ACCESS
    # =================================================================
    # Serve uploaded images directly from nginx for maximum performance
    # This bypasses the Node.js application for static file serving
    location /uploads {
        # Map /uploads URLs to the actual filesystem path
        alias /var/www/uploads;

        # Aggressive caching for images (they don't change once uploaded)
        expires 1y;                                    # Cache for 1 year
        add_header Cache-Control "public, immutable";  # Tell browsers files never change
        add_header X-Content-Type-Options nosniff;     # Security header

        # Security: Block execution of server-side scripts in uploads directory
        # This prevents malicious file uploads from being executed
        location ~* \.(php|pl|py|jsp|asp|sh|cgi)$ {
            deny all;
        }
    }

    # =================================================================
    # FRONTEND APPLICATION - STATIC WEBSITE
    # =================================================================
    # All other requests go to the Vue.js frontend application
    # This handles the main website, routing, and static assets
    location / {
        # Forward to the client upstream (Vue.js app served by nginx)
        proxy_pass http://client;
        
        proxy_http_version 1.1;
        
        # WebSocket support for development hot-reload
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
    }
}

# =====================================================================
# HTTPS SERVER BLOCK - PRODUCTION SSL CONFIGURATION
# =====================================================================
# This server block handles HTTPS traffic when you have SSL certificates
# Uncomment and configure this section for production deployments

# server {
#     # Listen on port 443 with SSL and HTTP/2 enabled
#     listen 443 ssl http2;
#     
#     # Replace with your actual domain name
#     server_name your-domain.com;
#
#     # ===============================================================
#     # SSL CERTIFICATE CONFIGURATION
#     # ===============================================================
#     # Path to your SSL certificate file (public key)
#     ssl_certificate /etc/nginx/ssl/cert.pem;
#     
#     # Path to your SSL private key file (keep this secure!)
#     ssl_certificate_key /etc/nginx/ssl/key.pem;
#     
#     # SSL session caching for better performance
#     ssl_session_timeout 1d;                    # Session cache lifetime
#     ssl_session_cache shared:MozTLS:10m;       # Shared session cache
#     ssl_session_tickets off;                   # Disable session tickets for security
#
#     # ===============================================================
#     # SSL SECURITY CONFIGURATION
#     # ===============================================================
#     # Only use modern, secure SSL/TLS protocols
#     ssl_protocols TLSv1.2 TLSv1.3;
#     
#     # Specify secure cipher suites (encryption algorithms)
#     ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384;
#     
#     # Let the client choose the cipher (better performance)
#     ssl_prefer_server_ciphers off;
#
#     # ===============================================================
#     # SECURITY HEADERS FOR HTTPS
#     # ===============================================================
#     # HTTP Strict Transport Security (HSTS) - force HTTPS for 2 years
#     add_header Strict-Transport-Security "max-age=63072000" always;
#
#     # ===============================================================
#     # LOCATION BLOCKS FOR HTTPS
#     # ===============================================================
#     # Copy all the location blocks from the HTTP server above:
#     # - /health
#     # - /api/
#     # - /api/upload
#     # - /uploads
#     # - /
#     
#     # (Include the same location blocks as HTTP server)
# }